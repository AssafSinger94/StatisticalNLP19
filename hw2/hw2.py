# -*- coding: utf-8 -*-
"""hw2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/156gNJC-gK7_0drSq-jZKv0rI8loBDame
"""

import numpy as np
from numpy import linalg as LA
import pandas as pd
import matplotlib.pyplot as plt
import time
import re
import string
from collections import Counter
from sklearn import preprocessing
from random import shuffle

# Remove if running locally on computer 
from google.colab import drive
drive.mount("/content/gdrive", force_remount=True)

# Files and directories
# Folder when running on Google Colab
folder = "/content/gdrive/My Drive/NLP2019/"
# # Folder when running local on computer 
# folder = ""
training_set_file_name = "pnp-train - Complete.txt"
validation_set_file_name = "pnp-validate.txt"
test_set_file_name = "pnp-test.txt"

# Threshold for minimum counts for sequences, below threshold sequence is not accounted in feature vector
COUNTS_THRESHOLD_HIGH = 80
COUNTS_THRESHOLD_MEDIUM = 50
COUNTS_THRESHOLD_LOW = 30

# Get all training set names
inputs = [line.rstrip('\n').lower().split('\t')[1] for line in open(folder + training_set_file_name, 'r', encoding='iso-8859-1')]

'''
Creates dictionary that assigns column/index number for each n-gram with more counts than threshold
:param n: length of n-gram
:param n_gram_counts_threshold: Threshold for counts in order to be included 
'''
def get_top_n_gram_dictionary(n, n_gram_counts_threshold):
    # Initialize n-gram counts dictionary
    n_gram_counts = {}
    for input in inputs:
    # Get over all n-grams, and set counts for each n-gram
        for i in range(max(len(input) - (n - 1), 0)):
            n_gram_counts[input[i: i + n]] = n_gram_counts.get(input[i: i + n], 0) + 1
    # Filter only n-gram with more counts than the specified threshold
    filtered_n_grams = {k: v for k, v in n_gram_counts.items() if v > n_gram_counts_threshold}
    # Convert each n-gram in filtered dictionary to index
    return {k: v for v, k in enumerate(filtered_n_grams.keys())}

#-----Unigrams-----
unigram_to_index = get_top_n_gram_dictionary(1, COUNTS_THRESHOLD_HIGH)
#-----Bigrams-----
bigram_to_index = get_top_n_gram_dictionary(2, COUNTS_THRESHOLD_HIGH)
#-----Trigrams-----
trigram_to_index = get_top_n_gram_dictionary(3, COUNTS_THRESHOLD_MEDIUM)
#-----4-grams-----
four_gram_to_index = get_top_n_gram_dictionary(4, COUNTS_THRESHOLD_MEDIUM)
#-----5-grams-----
five_gram_to_index = get_top_n_gram_dictionary(5, COUNTS_THRESHOLD_LOW)
#-----6-grams-----
six_gram_to_index = get_top_n_gram_dictionary(6, COUNTS_THRESHOLD_LOW)
#-----7-grams-----
seven_gram_to_index = get_top_n_gram_dictionary(7, COUNTS_THRESHOLD_LOW)
#-----8-grams-----
eight_gram_to_index = get_top_n_gram_dictionary(8, COUNTS_THRESHOLD_LOW)


class FeatureVector(object):
    '''
    classdocs
    '''


    def __init__(self):
        '''
        Constructor
        '''
        
    '''
    Converts name into n-gram counts vector, for specific n
    :param name: name/sentence/input to convert to feature vector
    :param n: length of n-gram
    :param n_gram_to_index: dictionary from n-gram to sequence
    '''
    def n_gram_vector(self, name, n, n_gram_to_index):
        # Initialize n-gram vector
        n_gram_vector = [0 for i in range(len(n_gram_to_index.items()))]
        # Turn name to lowercase
        name = name.lower()
        # Go over name and count n-gram using n-gram vector
        for i in range(max(len(name) - (n - 1), 0)):
            if (name[i: i + n] in n_gram_to_index):
                n_gram_vector[n_gram_to_index.get(name[i: i + n])] += 1
        return n_gram_vector
    
    def unigram_vector(self, name):
        return self.n_gram_vector(name, 1, unigram_to_index)

    def bigram_vector(self, name):
        return self.n_gram_vector(name, 2, bigram_to_index)

    def trigram_vector(self, name):
        return self.n_gram_vector(name, 3, trigram_to_index)

    def four_gram_vector(self, name):
        return self.n_gram_vector(name, 4, four_gram_to_index)
      
    def five_gram_vector(self, name):
        return self.n_gram_vector(name, 5, five_gram_to_index)
      
    def six_gram_vector(self, name):
        return self.n_gram_vector(name, 6, six_gram_to_index)
      
    def seven_gram_vector(self, name):
        return self.n_gram_vector(name, 7, seven_gram_to_index)
      
    def eight_gram_vector(self, name):
        return self.n_gram_vector(name, 8, eight_gram_to_index)
    
    
    def convert_to_feature_vector(self, name):
        feature_vector = self.unigram_vector(name) + self.bigram_vector(name) + self.trigram_vector(name) + self.four_gram_vector(name) + self.five_gram_vector(name) + self.six_gram_vector(name) + self.seven_gram_vector(name) + self.eight_gram_vector(name)
        return feature_vector

# Hyperparameters
LEARNING_RATE   = 0.25
EPSILON         = 0.2
LAMBDA_R        = 0.01
BATCH_SIZE      = 512
ITERATIONS      = 2000

# Dictionaries for class representation
class_label_to_number = {
    "drug" : 0,
    "person" : 1,
    "place" : 2,
    "movie" : 3,
    "company" : 4
    }

number_to_class_label = {k: v for v, k in class_label_to_number.items()}

# Feature vector converter
feature_vector = FeatureVector()


class Model(object):
    '''
    classdocs
    '''

    '''
    Constructor
    
    :param X: Matrix of inputs {Xi}i=1..m
    :param Y: Vector of corresponding class labels {Yi}i=1..m
    :param classes_count: Number of different class labels
    :param alpha: Learning rate of gradient ascent optimization
    :param epsilon: Halting threshold of gradient ascent optimization
    :param lambda_r: regularization value for loss function
    '''
    def __init__(self, X, Y, X_valid, Y_valid, classes_count, alpha, epsilon, lambda_r, batch_size, iterations):
        self.X          = X
        self.Y          = Y
        self.m          = self.X.shape[0]
        self.D_in       = self.X.shape[1]
        self.classes_count  = classes_count
        # W is matrix of dimensions (classes x input_dim)
        self.W          = np.random.uniform(0, 1,(self.classes_count, self.D_in))
        self.alpha      = alpha
        self.epsilon    = epsilon
        self.lambda_r   = lambda_r
        self.batch_size = batch_size
        self.batches_per_epoch = (self.m / self.batch_size) + 1
        self.iterations = iterations
        
        self.training_loss_history = []
        self.training_accuracy_history = []
        self.X_valid    = X_valid
        self.Y_valid    = Y_valid
        self.validation_loss_history = []
        self.validation_accuracy_history = []

    
    def all_conditional_prob(self, Xi):
        # Multiply features by weightes
        scores = np.dot(self.W, Xi.T)
        # scale so all values or zero or negative
        scores = np.subtract(scores, np.max(scores))
        # Make into exponent
        scores = np.exp(scores)
        # Compute sum of all scores
        scores_sum = np.sum(scores)
        # divide all scores by sum
        probabilities = scores / scores_sum
        # return probability list
        return probabilities
        
    '''
    Compute conditional probability P(y|Xi,W)
    Equal to exp(Wy*Xi)/sum( exp( Wy'*Xi)) 
    :param Xi: feature vector of input Xi (also known as f(Xi))
    :param y: Class label y (1D value/Scalar)
    '''
    def conditional_prob(self, Xi, y):
        # Get probability list of P(y|Xi,W) for all y
        probabilities = self.all_conditional_prob(Xi)
        # Return probability
        return probabilities[y]
    
    '''
    Indicator function I(y1 == y2). Returns 1 if y1==y2, 0 otherwise
    '''
    def indicator(self, y1, y2):
            return (1 if (y1 == y2) else 0)
        
    
    '''
    Computes gradient of loss function relative to Wy dL/dWy
    :param X: Matrix of inputs {Xi}i=1..m
    :param Y: Vector of corresponding class labels {Yi}i=1..m
    :param W: Weight Matrix
    :param y: class label in which gradient is calculated with respect to. (1D value/Scalar)
    :param lambdaR: Regularization ratio
    '''
    def compute_gradient_of_loss(self, X, Y, W, y):
        # Initialize dL/dWy to vector of zeroes (of dimension Wy) 
        dLdWy = np.zeros(self.D_in)
        # Get number of training points
        train_point_count = X.shape[0]
        for i in range(train_point_count):
            # Add dL/dWy for {Xi,Yi}
            dLdWy = np.add(dLdWy, X[i] * self.indicator(Y[i], y))
            dLdWy = np.subtract(dLdWy, X[i] * self.conditional_prob(X[i], y))
        dLdWy = np.subtract(dLdWy, 2 * self.lambda_r * W[y])
        return dLdWy
    
    '''
    Runs one iteration of string update: W = W + alpha*dL/dW
    '''
    def update_weights(self, start_point):
        #Initialize dLdW with random values 
        dLdW = np.zeros((self.classes_count, self.D_in))
        # Set end_point
        end_point = min(start_point + self.batch_size, self.m)
        # Go over for each y in classes, set dLdW[y] = dLdWy 
        for y in range(self.classes_count):
            dLdW[y] = self.compute_gradient_of_loss(self.X[start_point : end_point], self.Y[start_point : end_point], self.W, y)
        # W = W + alpha * dLdW
        self.W = np.add(self.W, self.alpha * dLdW)
                
    '''
    Computes loss function of Dataset with current weights W
    :param X: Matrix of inputs {Xi}i=1..m
    :param Y: Vector of class labels {Xi}i=1..m
    :param W: Weight Matrix
    :param lambdaR: Regularization ratio
    '''
    def loss(self, X, Y, W, lambda_r):
        # Total loss
        loss = 0.0
        # Go over every data point in data set, which is number of rows in X
        m = X.shape[0]
        for i in range(m):
            # Compute loss for {Xi,Yi}
            loss += np.log(self.conditional_prob(X[i], Y[i]))
        # Subtract regularization value
        loss -= lambda_r * np.square(LA.norm(W))
        return loss
      
    def accuracy(self, X, Y):
        y_pred = []
        correct_calls = 0.0
        
        # Go over every data point in data set, which is number of rows in X
        m = X.shape[0]
        for i in range(m):
            if (Y[i] == self.predict(X[i])):
                correct_calls += 1
        return correct_calls / m
    
    def fit(self):
        # Print model hyperparameters
        print("W dimensions:", self.W.shape)
        print ("alpha: ", self.alpha)
        print("epsilon: ", self.epsilon)
        print("lambda: ", self.lambda_r)
        print("batch size: ",  self.batch_size)
        print ("batches per epoch: "+"{:.1f}".format(self.batches_per_epoch))
        print ("iterations: ", self.iterations)
        # Initialize number of iterations, epochs, and starting point
        t = 0
        epoch = 0
        start_point = 0
        # set alpha_0
        alpha_0 = self.alpha
        # W is placeholder for self.W (to track change), initialized to self.W
        W = self.W
        # Save start_time time
        start_time = time.time()
        # Set previous loss for progress monitoring
        previous_loss = -5000000
        while ((t == 0) or (LA.norm(W - self.W) > self.epsilon)):
          
            if (start_point == 0 and t > 0):
                epoch += 1
                # Show progress details, iteration number, passed time, learning rate, total loss
                print("\nWeight update, Epoch ", epoch, ", Iteration ", t)
                current_time = time.time()
                print("Time passed: "+"{:.0f}".format(current_time - start_time))
                print("Current Learning rate: "+"{:.4f}".format(self.alpha))
                current_loss = self.loss(self.X, self.Y, self.W, self.lambda_r)
                print("Current loss: "+"{:.3f}".format(current_loss))
                print("Update size: "+"{:.4f}".format(LA.norm(W - self.W)))
                training_accuracy = self.accuracy(self.X, self.Y)
                print("Current training accuracy: "+"{:.4f}".format(training_accuracy))
                test_accuracy = self.accuracy(self.X_valid, self.Y_valid)
                print("Current test accuracy: "+"{:.4f}".format(test_accuracy))
                # If function not converging fast enough, notice and adjust learning rate
                if (current_loss < previous_loss or ((epoch + 1) % 10) == 0):
                    print("Loss not converging fast enough, applying extra Learning rate decay")
                    alpha_0 /= 2
                self.alpha = alpha_0 / (np.sqrt(epoch))
                print("New Learning rate: "+"{:.4f}".format(self.alpha))
                
                # Add current loss to training and test loss history
                self.training_loss_history.append( (-1) * current_loss)
                self.validation_loss_history.append((-8) * self.loss(self.X_valid, self.Y_valid, self.W, self.lambda_r))
                # Add current accuracy to training and test accuracy history
                self.training_accuracy_history.append(training_accuracy)
                self.validation_accuracy_history.append(test_accuracy)
                
                # Save loss for next update
                previous_loss = current_loss
            # Set W to current self.W, as placeholder for self.W
            W = self.W
            # Update self.W
            self.update_weights(start_point)
            # update start_point of next batch
            start_point += self.batch_size
            start_point = (0 if (start_point > self.m) else start_point)
            # Incrment t
            t += 1
            
        # Training over, show total loss
        print("-----Training over, Iteration:", t, "-----")
        current_time = time.time()
        print("Total Time passed: "+"{:.0f}".format(current_time - start_time))
        print("Final loss "+"{:.3f}".format(self.loss(self.X, self.Y, self.W, self.lambda_r)))
        print("Final training accuracy: "+"{:.4f}".format(self.accuracy(self.X, self.Y)))
        print("Final test accuracy: "+"{:.4f}".format(self.accuracy(self.X_valid, self.Y_valid)))
        
        
    def plot_loss(self, start_epoch):
        # Create count of the number of epochs
        epoch_count = range(start_epoch + 1, len(self.training_loss_history) + 1)
        # Visualize loss history
        plt.plot(epoch_count, self.training_loss_history[start_epoch : ], 'r-')
        plt.plot(epoch_count, self.validation_loss_history[start_epoch : ], 'b-')
        plt.legend(['Training Loss', 'Validation Loss'])
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.show();

    def plot_accuracy(self, start_epoch):
        # Create count of the number of epochs
        epoch_count = range(start_epoch + 1, len(self.training_accuracy_history) + 1)
        # Visualize accuracy history
        plt.plot(epoch_count, self.training_accuracy_history[start_epoch : ], 'r-')
        plt.plot(epoch_count, self.validation_accuracy_history[start_epoch : ], 'b-')
        plt.legend(['Training Accuracy', 'Validation Accuracy'])
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.show();
    
    
    def predict(self, X):
        # Get probability list of P(y|X,W) for all y
        probabilities = self.all_conditional_prob(X)
        # Return probability
        return np.argmax(probabilities)

#-----Data Preprocessing-----
def get_lines_shuffled(file_path):
    # Get all inputs and outputs
    inputs_outputs = [line.rstrip('\n').split('\t') for line in open(file_path, 'r', encoding='iso-8859-1')]
    # Shuffle data points to accelrate training
    shuffle(inputs_outputs)
    return inputs_outputs

def parse_data_set_shuffled(file_path):
    # Get list of [Class word, Name]
    data_set = get_lines_shuffled(file_path)
    # Create dictionary from class word to class label
    X = []
    Y = []
    for line in data_set:
        X.append(feature_vector.convert_to_feature_vector(line[1]))
        Y.append(class_label_to_number.get(line[0]))
        
    return np.array(X), np.array(Y)

  
def get_lines_ordered(file_path):
    # Get all inputs and outputs
    inputs_outputs = [line.rstrip('\n').split('\t') for line in open(file_path, 'r', encoding='iso-8859-1')]
    return inputs_outputs
  
def parse_data_set_ordered(file_path):
    # Get list of [Class word, Name]
    data_set = get_lines_ordered(file_path)
    # Create dictionary from class word to class label
    X = []
    Y = []
    for line in data_set:
        X.append(feature_vector.convert_to_feature_vector(line[1]))
        Y.append(class_label_to_number.get(line[0]))
        
    return np.array(X), np.array(Y)

#-----Training Model-----
# Get training set 
X_train, Y_train = parse_data_set_shuffled(folder + training_set_file_name)
# Get validation set 
X_valid, Y_valid = parse_data_set_shuffled(folder + validation_set_file_name)

# Set scaler for data set
scaler = preprocessing.MinMaxScaler()
# Scale training set
X_train = scaler.fit_transform(X_train)
# Scale validation set
X_valid = scaler.transform(X_valid)


# Initialize model
model = Model(X_train, Y_train, X_valid, Y_valid, len(class_label_to_number), LEARNING_RATE, EPSILON, LAMBDA_R, BATCH_SIZE, ITERATIONS)
# Train model
model.fit()
# Plot loss on training and test
model.plot_loss(0)
model.plot_loss(5)
# Plot accuracy on training and test
model.plot_accuracy(0)
model.plot_accuracy(5)

#-----Testing Model (On training set)-----
# Get set for validation
training_data_set_orderd = get_lines_ordered(folder + training_set_file_name)
X_train_ordered = parse_data_set_ordered(folder + training_set_file_name)[0]
X_train_ordered = scaler.transform(X_train_ordered)
y_actu = []
y_pred = []
correct_calls = 0.0

print("TRUE_OUT", "\t", "PREDICT", "\t", "INPUT")
for i in range(len(training_data_set_orderd)):
    y_actu.append(training_data_set_orderd[i][0])
    y_pred.append(number_to_class_label.get(model.predict(X_train_ordered[i])))
    x = training_data_set_orderd[i][1]
    print (y_actu[i], "\t", y_pred[i], "\t", x)
    if (y_actu[i] == y_pred[i]):
        correct_calls += 1
        
y_actu = pd.Series(y_actu, name='Actual')
y_pred = pd.Series(y_pred, name='Predicted')
confusion_matrix = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)


print("Accuracy: "+"{:.4f}".format(correct_calls / len(training_data_set)))
print("Confusion matrix:\n%s" % confusion_matrix)

#-----Testing Model (On validation set)-----
validation_data_set = get_lines(folder + validation_set_file_name)
X_valid_ordered = parse_data_set_ordered(folder + validation_set_file_name)[0]
X_valid_ordered = scaler.transform(X_valid_ordered)
y_actu = []
y_pred = []
correct_calls = 0.0

print("TRUE_OUT", "\t", "PREDICT", "\t", "INPUT")
for i in range(len(validation_data_set)):
    y_actu.append(validation_data_set[i][0])
    y_pred.append(number_to_class_label.get(model.predict(X_valid_ordered[i])))
    x = validation_data_set[i][1]
    print (y_actu[i], "\t", y_pred[i], "\t", x)
    if (y_actu[i] == y_pred[i]):
        correct_calls += 1
        
y_actu = pd.Series(y_actu, name='Actual')
y_pred = pd.Series(y_pred, name='Predicted')
confusion_matrix = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)

print("Accuracy: "+"{:.4f}".format(correct_calls / len(validation_data_set)))
print("Confusion matrix:\n%s" % confusion_matrix)

#-----Testing Model (On test set)-----
test_data_set = get_lines(folder + test_set_file_name)
X_test_ordered = parse_data_set_ordered(folder + test_set_file_name)[0]
X_test_ordered = scaler.transform(X_test_ordered)


print("PREDICT", "\t", "INPUT")
for i in range(len(test_data_set)):
    y_pred = number_to_class_label.get(model.predict(X_test_ordered[i]))
    x = test_data_set[i][1]
    print (y_pred, "\t", x)
